{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBLP Publication Key Data Spreadsheet Conversion\n",
    "\n",
    "We will be parsing the DBLP XML file for research publication records and extracting the title, conference, year published, and author tags\n",
    "With each publication, the script will determine the following:\n",
    "1. The author(s) affiliations\n",
    "2. The country in which the affiliated institutions are located (abbreviated)\n",
    "3. The geographic region in which the affiliated institutions are located (ie. asia, europe, north america)\n",
    "\n",
    "A final csv including the author, conference, date, school and location details of each article will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse DBLP XML file\n",
    "dblp_data = 'C:/Eric/Projects/datasets/uniranking_data/dblp2.xml'\n",
    "tree = ET.parse(dblp_data)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Load reference data\n",
    "locations = pd.read_csv('C:/Eric/Projects/AI_Rankings/data/country-info.csv')\n",
    "csr = pd.read_csv('C:/Eric/Projects/AI_Rankings/data/csrankings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack tile, conference, year, and authors from data\n",
    "def str_diff(page_num:str):\n",
    "    try:\n",
    "        n = page_num.split('-')\n",
    "        try:\n",
    "            n[0] = n[0].split(':')[0]\n",
    "            n[1] = n[1].split(':')[0]\n",
    "        except:\n",
    "            pass\n",
    "        pg = int(n[1]) - int(n[0])\n",
    "    except:\n",
    "        pg = 1\n",
    "\n",
    "    return pg\n",
    "\n",
    "def unpack(root):\n",
    "    cols = ['Title','Conference','Year','Authors']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    rows = []\n",
    "    pages = []\n",
    "\n",
    "    for p in root:\n",
    "        author_list = []\n",
    "        for author in p.findall('.//author'):\n",
    "            author_list.append(author.text)\n",
    "\n",
    "        try:\n",
    "            page_num = p.find('pages').text\n",
    "            pages.append(str_diff(page_num))\n",
    "        except AttributeError:\n",
    "            pages.append(0)\n",
    "\n",
    "\n",
    "        row = {'Title': p.find('title').text, \n",
    "            'Conference': p.attrib['key'].split('/')[1], \n",
    "            'Year': int(p.find('year').text),\n",
    "            'Authors': author_list,}\n",
    "        rows.append(row)\n",
    "\n",
    "    rows_df = pd.DataFrame(rows)\n",
    "    df = pd.concat([df, rows_df], ignore_index=True)\n",
    "    return df, pages\n",
    "\n",
    "publications,pg = unpack(root)\n",
    "\n",
    "# gather affiliation and location info from author data\n",
    "inst_list = []\n",
    "country_list = []\n",
    "region_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132704\n"
     ]
    }
   ],
   "source": [
    "print(len([num for num in pg if num < 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 371832/371832 [39:59<00:00, 154.95it/s] \n"
     ]
    }
   ],
   "source": [
    "# find country of list of institutions   \n",
    "def find_inst_country(country_info:pd.DataFrame,inst_list:list):\n",
    "    countries = []\n",
    "    for inst in inst_list:\n",
    "        country = country_info[country_info['institution'] == inst]['countryabbrv']\n",
    "        if not country.empty:\n",
    "            countries.append(country.iloc[0])\n",
    "        else:\n",
    "            countries.append('us')\n",
    "    return set(countries)\n",
    "\n",
    "# find multiple author affiliation\n",
    "def find_author_affil(authors:list,csr:pd.DataFrame):\n",
    "    affils = []\n",
    "    for author in authors:\n",
    "        try:\n",
    "            inst = csr[csr['name'] == author]['affiliation']\n",
    "            affils.append(inst.iloc[0])\n",
    "        except:\n",
    "            continue\n",
    "    return set(affils)\n",
    "\n",
    "# find region of list of institutions   \n",
    "def find_country_region(country_info:pd.DataFrame,country_list:list):\n",
    "    regs = []\n",
    "    for c in country_list:\n",
    "        reg = country_info[country_info['countryabbrv'] == c]['region']\n",
    "        if not reg.empty:\n",
    "            regs.append(reg.iloc[0])\n",
    "        else:\n",
    "            regs.append('us')\n",
    "    return set(regs)\n",
    "\n",
    "# map location data of institutions\n",
    "for _, row in tqdm(publications.iterrows(), total=publications.shape[0]):\n",
    "    authors = row['Authors']\n",
    "\n",
    "    affils = find_author_affil(authors,csr)\n",
    "    inst_list.append(affils)\n",
    "\n",
    "    countries = find_inst_country(locations,affils)\n",
    "    country_list.append(countries)\n",
    "\n",
    "    region = find_country_region(locations,countries)\n",
    "    region_list.append(region)\n",
    "\n",
    "publications['Affiliations'] = inst_list\n",
    "publications['Countries'] = country_list\n",
    "publications['Region'] = region_list\n",
    "\n",
    "# Since we are only interested in publications authored by faculty from academic institutions,\n",
    "# we will filter out publications by authors with no affiliated institutions at the moment (corporate researchers, etc.)\n",
    "result = publications[publications['Affiliations'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "print('Remaining publications:', len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data editor\n",
    "def replace_set(s, country, region):\n",
    "    if country in s:\n",
    "        s.remove(country)\n",
    "        s.add(region)\n",
    "    return s\n",
    "\n",
    "def join_authors(authors):\n",
    "    return ', '.join(authors) if isinstance(authors, list) else authors\n",
    "\n",
    "# the default region labling by csranking lists us and canada individually\n",
    "# we will group them together into northamerica for consistency\n",
    "if any('us' in s for s in result['Region']):\n",
    "    #result['Region'] = result['Region'].apply(ast.literal_eval)\n",
    "    result['Region'] = result['Region'].apply(lambda s: replace_set(s, 'us', 'northamerica'))\n",
    "    result['Region'] = result['Region'].apply(lambda s: replace_set(s, 'canada', 'northamerica'))\n",
    "\n",
    "# only for formatting purposes we will remove the [] and {} from the sets\n",
    "# by joining these sets as one concatenated string\n",
    "result['Affiliations'] = result['Affiliations'].apply(', '.join)\n",
    "result['Countries'] = result['Countries'].apply(', '.join)\n",
    "result['Region'] = result['Region'].apply(', '.join)\n",
    "result['Authors'] = result['Authors'].apply(join_authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as Excel Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory usage: 111.91538 MB\n"
     ]
    }
   ],
   "source": [
    "# save as csv\n",
    "filename = \"DBLP_publications.csv\"\n",
    "result.to_csv(filename,index=False)\n",
    "\n",
    "# check memory usage\n",
    "total_memory_usage = result.memory_usage(deep=True).sum()\n",
    "print(\"Total memory usage:\", total_memory_usage/1000000, \"MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
